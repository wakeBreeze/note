

### 复杂度分析



*什么是复杂度分析？*

1.数据结构和算法解决是“如何让计算机更快时间、更省空间的解决问题”。
2.因此需从执行时间和占用空间两个维度来评估数据结构和算法的性能。
3.分别用时间复杂度和空间复杂度两个概念来描述性能问题，二者统称为复杂度。
4.复杂度描述的是算法执行时间（或占用空间）与数据规模的增长关系。



*为什么要进行复杂度分析？*

1.和性能测试相比，复杂度分析有不依赖执行环境、成本低、效率高、易操作、指导性强的特点。

2.掌握复杂度分析，将能编写出性能更优的代码，有利于降低系统开发和维护成本。



*如何进行复杂度分析？*

1.大O表示法

1）来源
算法的执行时间与每行代码的执行次数成正比，用T(n) = O(f(n))表示，其中T(n)表示算法执行总时间，f(n)表示每行代码执行总次数，而n往往表示数据的规模。

2）特点
以时间复杂度为例，由于时间复杂度描述的是算法执行时间与数据规模的增长==变化趋势==，所以常量阶、低阶以及系数实际上对这种增长趋势不产决定性影响，所以在做时间复杂度分析时忽略这些项。

2.复杂度分析法则

1）单段代码看高频：比如循环。

2）多段代码取最大：比如一段代码中有单循环和多重循环，那么取多重循环的复杂度。

3）嵌套代码求乘积：比如递归、多重循环等

4）多个规模求加法：比如方法有两个参数控制两个循环的次数，那么这时就取二者复杂度相加。



*常用的复杂度级别？*

多项式阶：随着数据规模的增长，算法的执行时间和空间占用，按照多项式的比例增长。包括，
O(1)（常数阶）、O(logn)（对数阶）、O(n)（线性阶）、O(nlogn)（线性对数阶）、O(n^2^)（平方阶）、O(n^3^)（立方阶）

非多项式阶：随着数据规模的增长，算法的执行时间和空间占用暴增，这类算法性能极差。包括，
O(2^n^)（指数阶）、O(n!)（阶乘阶）



*如何掌握好复杂度分析方法？*

复杂度分析关键在于多练，所谓孰能生巧。



*复杂度分析的4个概念：*

**最好时间复杂度：**代码在最理想情况下执行的时间复杂度。

**最坏时间复杂度：**代码在最坏情况下执行的时间复杂度。

**平均时间复杂度：**用代码在所有情况下执行的次数的加权平均值表示。

**均摊时间复杂度：**在代码执行的所有复杂度情况中绝大部分是低级别的复杂度，个别情况是高级别复杂度且发生具有时序关系时，可以将个别高级别复杂度均摊到低级别复杂度上。基本上均摊结果就等于低级别复杂度。



*为什么要引入这4个概念？*

1.同一段代码在不同情况下时间复杂度会出现量级差异，为了更全面，更准确的描述代码的时间复杂度，所以引入这4个概念。

2.代码复杂度在不同情况下出现量级差别时才需要区别这四种复杂度。大多数情况下，是不需要区别分析它们的。



*如何分析平均、均摊时间复杂度？*

1.平均时间复杂度
代码在不同情况下复杂度出现量级差别，则用代码所有可能情况下执行次数的加权平均值表示。

2.均摊时间复杂度
两个条件满足时使用：1）代码在绝大多数情况下是低级别复杂度，只有极少数情况是高级别复杂度；2）低级别和高级别复杂度出现具有时序规律。均摊结果一般都等于低级别复杂度。



### 数组



定义：数组（Array）是一种==线性表数据结构==。它用一组==连续的==内存空间，来存储一组具有==相同类型==的数据。

第一是线性表（Linear List）。顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了==数组，链表、队列、栈等也是线性表结构（二叉树、堆、图等是非线性）==。

![img](https://static001.geekbang.org/resource/image/b6/77/b6b71ec46935130dff5c4b62cf273477.jpg)

![img](https://static001.geekbang.org/resource/image/6e/69/6ebf42641b5f98f912d36f6bf86f6569.jpg)



第二是连续的内存空间和相同类型的数据。正是因为这两个限制，才有了“随机访问”的特性。但这两个限制也让数组的增加、删除、插入数据变得复杂，为了保证连续性，就需要做大量的数据搬移工作。



*根据下表随机访问数组元素的原理*

举例：

我们拿一个长度为 10 的 int 类型的数组 int[] a = new int[10]来举例。在我画的这个图中，计算机给数组 a[10]，分配了一块连续内存空间 1000～1039，其中，内存块的首地址为 base_address = 1000。

![img](https://static001.geekbang.org/resource/image/98/c4/98df8e702b14096e7ee4a5141260cdc4.jpg)

计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址：

```java
//base_address 数组首地址
//i 数组下标
//data_type_size 数组元素大小（int大小为4字节）

a[i]_address = base_address + i * data_type_size
```

数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)  （而并非随机访问数组元素的时间复杂度为O(1)）



*低效的“插入”和“删除”*

插入操作：

数组存储数据有规律：

​	数组为了保持内存数据的连续性，会导致插入、删除这两个操作比较低效。平均时间复杂度为O(n)

数组存储数据无规律：

​	如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数据插入到第 k 个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置

![img](https://static001.geekbang.org/resource/image/3f/dc/3f70b4ad9069ec568a2caaddc231b7dc.jpg)

此时插入元素的时间复杂度为O(1)。



删除操做：

如果删除数组末尾的数据，则最好情况时间复杂度为 O(1)；如果删除开头的数据，则最坏情况时间复杂度为 O(n)；平均情况时间复杂度也为 O(n)。

实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？

举例：

数组 a[10]中存储了 8 个元素：a，b，c，d，e，f，g，h。现在，我们要依次删除 a，b，c 三个元素。

![img](https://static001.geekbang.org/resource/image/b6/e5/b69b8c5dbf6248649ddab7d3e7cfd7e5.jpg)

为了避免 d，e，f，g，h 这几个数据会被搬移三次，我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。

这也是JVM的标记清除垃圾回收算法的核心思想。



*容器能否完全替代数组？*

1. Java ArrayList 无法存储基本类型，比如 int、long，需要封装为 Integer、Long 类，而 Autoboxing、Unboxing 则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组。

2. 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。
3. 当要表示多维数组时，用数组往往会更加直观。比如 Object[] [] array；而用容器的话则需要这样定义：ArrayList<ArrayList<object>> array。

业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。

非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。



问题: 为什么大多数编程语言中，数组要从 0 开始编号，而不是从 1 开始呢？

从数组存储的内存模型上来看，“下标”最确切的定义应该是“偏移（offset）”。如果用 a 来表示数组的首地址，a[0]就是偏移为 0 的位置，也就是首地址，a[k]就表示偏移 k 个 type_size 的位置，所以计算 a[k]的内存地址只需要用这个公式：

```java
a[k]_address = base_address + k * type_size
```

但是，如果数组从 1 开始计数，那我们计算数组元素 a[k]的内存地址就会变为：

```Java
a[k]_address = base_address + (k-1)*type_size
```

对比两个公式，从 1 开始编号，每次随机访问数组元素都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令。

数组作为非常基础的数据结构，通过下标随机访问数组元素又是其非常基础的编程操作，效率的优化就要尽可能做到极致。所以为了减少一次减法操作，数组选择了从 0 开始编号，而不是从 1 开始。

可能历史原因:C语言设计者用0作为数组下标开始位置,其他语言效仿.



*思考*

1. 回顾下你理解的标记清除垃圾回收算法。
2. 类比一下一维数组的内存寻址公式，二维数组的内存寻址公式是怎样的呢？

JVM标记清除算法：

大多数主流虚拟机采用可达性分析算法来判断对象是否存活，在标记阶段，会遍历所有 GC ROOTS，将所有 GC ROOTS 可达的对象标记为存活。只有当标记工作完成后，清理工作才会开始。

不足：1.效率问题。标记和清理效率都不高，但是当知道只有少量垃圾产生时会很高效。2.空间问题。会产生不连续的内存空间碎片。

二维数组内存寻址：

对于 m * n 的数组，a [ i ] [ j ] (i < m,j < n)的地址为：

address = base_address + ( i * n + j) * type_size

另外，对于数组访问越界造成无限循环，我理解是编译器的问题，对于不同的编译器，在内存分配时，会按照内存地址递增或递减的方式进行分配。老师的程序，如果是内存地址递减的方式，就会造成无限循环。
