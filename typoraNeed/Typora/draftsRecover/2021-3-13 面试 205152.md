### HashSet

HashSet的存储原理或者工作原理，主要是从如何保证唯一性来说起。





第三，HashSet如何保证保存对象的唯一性？会经历一个什么样的运算过程？



HashSet底层使用HashMap进行存储，add的参数作为HashMap的key，因此不能重复。

```java
private static final object PRESENT = new Object();

public boolean add(E e){
    return map.put(e，PRESENT)==null;//PRESENT是用来填充的空对象。
}
```



第一，为什么要采用Hash算法？有什么优势，解决了什么问题？

解决唯一性问题

存储数据，底层采用的是数组

往数组存放数据的时候，如何判断唯一性？

遍历，逐个比较，但是效率低

解决效率低下的问题：采用哈市算法，通过计算存储对象的hashcode，然后再跟数组长度-1做位运算，得到我们要存储在数组的那个下标下，如果此时计算的位置没有其他元素，直接存储，不用比较。

此处，我们只会用到hashcode

但是随着元素的不断增加，就可能出现“哈希冲突”，不同的对象计算出来的hash值相同，这是，我们就需要比较，才需要用到equals方法

如果equals相同，则不插入，不同则形成链表



第二，所谓的哈希表是一张什么表？

本质是一个数组，数组的元素是链表



以上是JDK1.7的版本实现

JDK1.8做了优化

随着元素不断增加，链表越来越长，会优化为红黑树



### ArrayList 和 Vector

ArrayList：线程不安全，效率高，常用

Vector：线程安全（内部使用Synchronized关键字修饰），效率低



### Hashtable & HashMap & ConcurrentHashMap

Hashtable：线程安全（内部put，get，remove等方法用Synchronized修饰），效率不高

HashMap：线程不安全，效率高，（多个线程同时操作这一个HashMap，可能出现线程不安全情况，甚至死锁）

Collections.synchronizedMap()，工具类提供了同步包装器的方法，来返回具有线程安全的集合对象，但是性能依然有问题

```java
public static <K,V> Map<K,V> synchronizedMap(Map<K,V> m) {
        return new SynchronizedMap<>(m);
    }
public V put(K key, V value) {
    		//加锁
            synchronized (mutex) {return m.put(key, value);}
        }
```



**ConcurrentHashMap**：分段锁，将锁的粒度变小	兼顾性能和安全

[详细](https://mp.weixin.qq.com/s/cnpfLL4TeL2oyEcHia6Bmg)

![image-20210313201929051](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210313201929051.png)

1. ConcurrentHashMap实现原理是怎么样的或者ConcurrentHashMap如何在保证高并发下线程安全的同时实现了性能提升？

> ❝
>
> `ConcurrentHashMap`允许多个修改操作并发进行，其关键在于使用了锁分离技术。它使用了多个锁来控制对hash表的不同部分进行的修改。内部使用段(`Segment`)来表示这些不同的部分，每个段其实就是一个小的`HashTable`，只要多个修改操作发生在不同的段上，它们就可以并发进行。
>
> ❞

1. 在高并发下的情况下如何保证取得的元素是最新的？

> ❝
>
> 用于存储键值对数据的`HashEntry`，在设计上它的成员变量value跟`next`都是`volatile`类型的，这样就保证别的线程对value值的修改，get方法可以马上看到。
>
> ❞

ConcurrentHashMap的弱一致性体现在迭代器,clear和get方法，原因在于没有加锁。

1. 比如迭代器在遍历数据的时候是一个Segment一个Segment去遍历的，如果在遍历完一个Segment时正好有一个线程在刚遍历完的Segment上插入数据，就会体现出不一致性。clear也是一样。
2. get方法和containsKey方法都是遍历对应索引位上所有节点，都是不加锁来判断的，如果是修改性质的因为可见性的存在可以直接获得最新值，不过如果是新添加值则无法保持一致性。



JDK8相比与JDK7主要区别如下：

> ❝
>
> 1. 取消了segment数组，直接用table保存数据，锁的粒度更小，减少并发冲突的概率。采用table数组元素作为锁，从而实现了对每一行数据进行加锁，进一步减少并发冲突的概率，并发控制使用Synchronized和CAS来操作。
> 2. 存储数据时采用了数组+ 链表+红黑树的形式。
>
> ❞

1. CurrentHashMap重要参数：

> ❝
>
> private static final int MAXIMUM_CAPACITY = 1 << 30; // 数组的最大值 
>
> private static final int DEFAULT_CAPACITY = 16; // 默认数组长度 
>
> static final int TREEIFY_THRESHOLD = 8; // 链表转红黑树的一个条件 
>
> static final int UNTREEIFY_THRESHOLD = 6; // 红黑树转链表的一个条件 
>
> static final int MIN_TREEIFY_CAPACITY = 64; // 链表转红黑树的另一个条件
>
> static final int MOVED   = -1;  // 表示正在扩容转移 
>
> static final int TREEBIN  = -2; // 表示已经转换成树 
>
> static final int RESERVED  = -3; // hash for transient reservations 
>
> static final int HASH_BITS = 0x7fffffff; // 获得hash值的辅助参数
>
> transient volatile Node<K,V>[] table;// 默认没初始化的数组，用来保存元素 
>
> private transient volatile Node<K,V>[] nextTable; // 转移的时候用的数组 
>
> static final int NCPU = Runtime.getRuntime().availableProcessors();// 获取可用的CPU个数 
>
> private transient volatile Node<K,V>[] nextTable; // 连接表，用于哈希表扩容，扩容完成后会被重置为 null 
>
> private transient volatile long baseCount;保存着整个哈希表中存储的所有的结点的个数总和，有点类似于 HashMap 的 size 属性。private transient volatile int `sizeCtl`; 
>
> 负数：表示进行初始化或者扩容，-1：表示正在初始化，-N：表示有 N-1 个线程正在进行扩容 正数：0 表示还没有被初始化，> 0的数：初始化或者是下一次进行扩容的阈值，有点类似HashMap中的`threshold`，不过功能**「更强大」**。



### 如何写一个Stack

先进后出，数组

入栈：stack[index++]=new Object()

出栈：stack[stack.length-1]